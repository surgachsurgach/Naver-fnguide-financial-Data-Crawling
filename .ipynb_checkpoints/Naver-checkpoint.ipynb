{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6w-iSBMZ389I"
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "\n",
    "\n",
    "class Naver:\n",
    "    ##date 형식 맞춰주기\n",
    "    def date_format(self, d=''):\n",
    "        if d != '':\n",
    "            this_date = pd.to_datetime(d).date()\n",
    "        else:\n",
    "            this_date = pd.Timestamp.today().date()   # 오늘 날짜를 지정\n",
    "        return (this_date)\n",
    "    \n",
    "\n",
    "    ##개별종목 주가수집 함수\n",
    "    def stock_price(self, historical_prices, stock_cd, start_date='', end_date='', page_n=1, last_page=0):\n",
    "\n",
    "        #nvr = self.NaverPrice()\n",
    "        start_date = self.date_format(start_date)\n",
    "        end_date = self.date_format(end_date)\n",
    "\n",
    "        naver_stock = 'http://finance.naver.com/item/sise_day.nhn?code=' + stock_cd + '&page=' + str(page_n)\n",
    "\n",
    "        source = urlopen(naver_stock).read()\n",
    "        source = bs4.BeautifulSoup(source, 'lxml')\n",
    "\n",
    "        dates = source.find_all('span', class_='tah p10 gray03')   # 날짜 수집   \n",
    "        prices = source.find_all('td', class_='num')   # 종가 수집\n",
    "        \n",
    "        for n in range(len(dates)):\n",
    "\n",
    "            if len(dates) > 0:\n",
    "\n",
    "                # 날짜 처리\n",
    "                this_date = dates[n].text\n",
    "                this_date = self.date_format(this_date)\n",
    "\n",
    "                if this_date <= end_date and this_date >= start_date:   \n",
    "                # start_date와 end_date 사이에서 데이터 저장\n",
    "                    # 종가 처리\n",
    "                    this_close = prices[n*6].text\n",
    "                    this_close = this_close.replace(',', '')\n",
    "                    this_close = float(this_close)\n",
    "\n",
    "                    # 딕셔너리에 저장\n",
    "                    historical_prices[this_date] = this_close\n",
    "\n",
    "                elif this_date < start_date:   \n",
    "                # start_date 이전이면 함수 종료\n",
    "                    return (historical_prices)              \n",
    "\n",
    "        # 페이지 네비게이션\n",
    "        if last_page == 0:\n",
    "            last_page = source.find_all('table')[1].find('td', class_='pgRR').find('a')['href']\n",
    "            last_page = last_page.split('&')[1]\n",
    "            last_page = last_page.split('=')[1]\n",
    "            last_page = float(last_page)\n",
    "\n",
    "        # 다음 페이지 호출\n",
    "        if page_n < last_page:\n",
    "            page_n = page_n + 1\n",
    "            self.stock_price(historical_prices, stock_cd, start_date, end_date, page_n, last_page)   \n",
    "\n",
    "        return (historical_prices)\n",
    "\n",
    "    ##지수 수집\n",
    "    def index_korea(self, historical_prices, index_cd, start_date='', end_date='', page_n=1, last_page=0):\n",
    "    \n",
    "        start_date = self.date_format(start_date)\n",
    "        end_date = self.date_format(end_date)\n",
    "\n",
    "        naver_index = 'http://finance.naver.com/sise/sise_index_day.nhn?code=' + index_cd + '&page=' + str(page_n)\n",
    "\n",
    "        source = urlopen(naver_index).read()   # 지정한 페이지에서 코드 읽기\n",
    "        source = bs4.BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "        dates = source.find_all('td', class_='date')   # <td class=\"date\">태그에서 날짜 수집   \n",
    "        prices = source.find_all('td', class_='number_1')   # <td class=\"number_1\">태그에서 지수 수집\n",
    "\n",
    "        for n in range(len(dates)):\n",
    "\n",
    "            if dates[n].text.split('.')[0].isdigit():\n",
    "\n",
    "                # 날짜 처리\n",
    "                this_date = dates[n].text\n",
    "                this_date= self.date_format(this_date)\n",
    "\n",
    "                if this_date <= end_date and this_date >= start_date:   \n",
    "                # start_date와 end_date 사이에서 데이터 저장\n",
    "                    # 종가 처리\n",
    "                    this_close = prices[n*4].text   # prices 중 종가지수인 0,4,8,...번째 데이터 추출\n",
    "                    this_close = this_close.replace(',', '')\n",
    "                    this_close = float(this_close)\n",
    "\n",
    "                    # 딕셔너리에 저장\n",
    "                    historical_prices[this_date] = this_close\n",
    "\n",
    "                elif this_date < start_date:   \n",
    "                # start_date 이전이면 함수 종료\n",
    "                    return (historical_prices)              \n",
    "\n",
    "        # 페이지 네비게이션\n",
    "        if last_page == 0:\n",
    "            last_page = source.find('td', class_='pgRR').find('a')['href']\n",
    "            # 마지막페이지 주소 추출\n",
    "            last_page = last_page.split('&')[1]   # & 뒤의 page=506 부분 추출\n",
    "            last_page = last_page.split('=')[1]   # = 뒤의 페이지번호만 추출\n",
    "            last_page = int(last_page)   # 숫자형 변수로 변환\n",
    "\n",
    "        # 다음 페이지 호출\n",
    "        if page_n < last_page:   \n",
    "            page_n = page_n + 1   \n",
    "            self.index_korea(historical_prices, index_cd, start_date, end_date, page_n, last_page)   \n",
    "\n",
    "        return (historical_prices)  \n",
    "    \n",
    "    ## 구성종목 기본정보\n",
    "    def stock_info(self, stock_cd):\n",
    "        url_float = 'http://companyinfo.stock.naver.com/v1/company/c1010001.aspx?cmp_cd=' + stock_cd\n",
    "        source = urlopen(url_float).read()\n",
    "        soup = bs4.BeautifulSoup(source, 'lxml')\n",
    "\n",
    "        tmp = soup.find(id='cTB11').find_all('tr')[6].td.text\n",
    "        tmp = tmp.replace('\\r', '')\n",
    "        tmp = tmp.replace('\\n', '')\n",
    "        tmp = tmp.replace('\\t', '')\n",
    "\n",
    "        tmp = re.split('/', tmp)\n",
    "\n",
    "        outstanding = tmp[0].replace(',', '')\n",
    "        outstanding = outstanding.replace('주', '')\n",
    "        outstanding = outstanding.replace(' ', '')\n",
    "        outstanding = int(outstanding)\n",
    "\n",
    "        floating = tmp[1].replace(' ', '')\n",
    "        floating = floating.replace('%', '')\n",
    "        floating = float(floating)\n",
    "\n",
    "        name = soup.find(id='pArea').find('div').find('div').find('tr').find('td').find('span').text\n",
    "\n",
    "        #k10_outstanding[stock_cd] = outstanding\n",
    "        #k10_floating[stock_cd] = floating\n",
    "        #k10_name[stock_cd] = name    \n",
    "        \n",
    "        return (name, outstanding, floating)\n",
    "\n",
    "    \n",
    "    \n",
    "    def index_global(self, d, symbol, start_date='', end_date='', page=1):\n",
    "\n",
    "        end_date = self.date_format(end_date)\n",
    "        if start_date == '':\n",
    "            start_date = end_date - pd.DateOffset(years=1)\n",
    "        start_date = self.date_format(start_date)\n",
    "\n",
    "        url = 'https://finance.naver.com/world/worldDayListJson.nhn?symbol='+symbol+'&fdtc=0&page='+str(page)\n",
    "        raw = urlopen(url)\n",
    "        data = json.load(raw)\n",
    "\n",
    "        if len(data) > 0:\n",
    "\n",
    "            for n in range(len(data)):\n",
    "                date = pd.to_datetime(data[n]['xymd']).date()\n",
    "\n",
    "                if date <= end_date and date >= start_date:   \n",
    "                # start_date와 end_date 사이에서 데이터 저장\n",
    "                    # 종가 처리\n",
    "                    price = float(data[n]['clos'])\n",
    "                    # 딕셔너리에 저장\n",
    "                    d[date] = price\n",
    "                elif date < start_date:   \n",
    "                # start_date 이전이면 함수 종료\n",
    "                    return (d)              \n",
    "\n",
    "            if len(data) == 10:\n",
    "                page += 1\n",
    "                self.index_global(d, symbol, start_date, end_date, page)\n",
    "\n",
    "        return (d)\n",
    "    \n",
    "    \n",
    "class NaverStockInfo:\n",
    "    ##기업정보\n",
    "    def read_src(self, stock_cd):\n",
    "        url_float = 'http://companyinfo.stock.naver.com/v1/company/c1010001.aspx?cmp_cd=' + stock_cd\n",
    "        source = urlopen(url_float).read()\n",
    "        soup = bs4.BeautifulSoup(source, 'lxml')\n",
    "        return (soup)\n",
    "        \n",
    "    \n",
    "    def stock_info(self, stock_cd):\n",
    "        url_float = 'http://companyinfo.stock.naver.com/v1/company/c1010001.aspx?cmp_cd=' + stock_cd\n",
    "        source = urlopen(url_float).read()\n",
    "        soup = bs4.BeautifulSoup(source, 'lxml')\n",
    "\n",
    "        tmp = soup.find(id='cTB11').find_all('tr')[6].td.text\n",
    "        tmp = tmp.replace('\\r', '')\n",
    "        tmp = tmp.replace('\\n', '')\n",
    "        tmp = tmp.replace('\\t', '')\n",
    "\n",
    "        tmp = re.split('/', tmp)\n",
    "\n",
    "        outstanding = tmp[0].replace(',', '')\n",
    "        outstanding = outstanding.replace('주', '')\n",
    "        outstanding = outstanding.replace(' ', '')\n",
    "        outstanding = int(outstanding)\n",
    "\n",
    "        floating = tmp[1].replace(' ', '')\n",
    "        floating = floating.replace('%', '')\n",
    "        floating = float(floating)\n",
    "\n",
    "        name = soup.find(id='pArea').find('div').find('div').find('tr').find('td').find('span').text\n",
    "       \n",
    "        return (name, outstanding, floating)\n",
    "      \n",
    "    ##발행주식수\n",
    "    def outstanding(self, stock_cd):\n",
    "        soup = self.read_src(stock_cd)\n",
    "        tmp = soup.find(id='cTB11').find_all('tr')[6].td.text\n",
    "        tmp = tmp.replace('\\r', '')\n",
    "        tmp = tmp.replace('\\n', '')\n",
    "        tmp = tmp.replace('\\t', '')\n",
    "        tmp = re.split('/', tmp)\n",
    "        outstanding = tmp[0].replace(',', '')\n",
    "        outstanding = outstanding.replace('주', '')\n",
    "        outstanding = outstanding.replace(' ', '')\n",
    "        outstanding = int(outstanding)\n",
    "        return (outstanding)\n",
    "      \n",
    "    ##유동주식수\n",
    "    def floating(self, stock_cd):\n",
    "        soup = self.read_src(stock_cd)\n",
    "        tmp = soup.find(id='cTB11').find_all('tr')[6].td.text\n",
    "        tmp = tmp.replace('\\r', '')\n",
    "        tmp = tmp.replace('\\n', '')\n",
    "        tmp = tmp.replace('\\t', '')\n",
    "        tmp = re.split('/', tmp)\n",
    "        floating = tmp[1].replace(' ', '')\n",
    "        floating = floating.replace('%', '')\n",
    "        floating = float(floating)\n",
    "        return (floating)\n",
    "    \n",
    "    ##formatting\n",
    "    def float_convert(self, s):\n",
    "        try:\n",
    "            s = s.replace(' ', '')\n",
    "            s = s.replace(',', '')\n",
    "            if re.findall('억', s):\n",
    "                m = 100000000\n",
    "                s = s.replace('억', '')\n",
    "            elif re.findall('백만', s):\n",
    "                m = 1000000\n",
    "                s = s.replace('백만', '')\n",
    "            if re.findall('%', s):\n",
    "                m = 0.01\n",
    "                s = s.replace('%', '')\n",
    "            s = s.replace('원', '')\n",
    "            f = float(s) * m\n",
    "        except:\n",
    "            f = s\n",
    "        return (f)\n",
    "    \n",
    "    ##fundamental\n",
    "    def fundamentals(self, stock_cd, f):\n",
    "        factors = dict()\n",
    "        soup = self.read_src(stock_cd)\n",
    "        rows = len(soup.find_all('div', class_='fund fl_le')[0].find_all('tr'))\n",
    "        for r in range(1, rows, 1):\n",
    "            title = soup.find_all('div', class_='fund fl_le')[0].find_all('tr')[r].find_all('th')[0].text\n",
    "            value_current = soup.find_all('div', class_='fund fl_le')[0].find_all('tr')[r].find_all('td')[0].text\n",
    "            value_current = self.float_convert(value_current)\n",
    "            value_estimated = soup.find_all('div', class_='fund fl_le')[0].find_all('tr')[r].find_all('td')[1].text\n",
    "            value_estimated = self.float_convert(value_estimated)\n",
    "            factors[title] = [value_current, value_estimated]\n",
    "            print(title, value_current, value_estimated)\n",
    "        return (factors[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ObCmm4Ty4Vbn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Naver.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
